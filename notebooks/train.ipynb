{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://github.com/F-Serra/MIDI-LSTM/blob/master/train.py\r\n",
    "# I could adapt this script to work for our MIDI model.\r\n",
    "\r\n",
    "def train(args):\r\n",
    "    # Load Data on Data Loader\r\n",
    "\r\n",
    "    # check compatibility if training is continued from previously saved model\r\n",
    "    if args.init_from is not None:\r\n",
    "        # check if all necessary files exist\r\n",
    "        assert os.path.isdir(args.init_from),\" %s must be a a path\" % args.init_from\r\n",
    "        assert os.path.isfile(os.path.join(args.init_from,\"config.pkl\")),\"config.pkl file does not exist in path %s\"%args.init_from\r\n",
    "        ckpt = tf.train.get_checkpoint_state(args.init_from)\r\n",
    "        assert ckpt, \"No checkpoint found\"\r\n",
    "        assert ckpt.model_checkpoint_path, \"No model path found in checkpoint\"\r\n",
    "\r\n",
    "    if not os.path.isdir(args.save_dir):\r\n",
    "        os.makedirs(args.save_dir)\r\n",
    "    with open(os.path.join(args.save_dir, 'config.pkl'), 'wb') as f:\r\n",
    "        cPickle.dump(args, f)\r\n",
    "\r\n",
    "    model = Model(args)\r\n",
    "\r\n",
    "    with tf.Session() as sess:\r\n",
    "        # restore model\r\n",
    "        if args.init_from is not None:\r\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\r\n",
    "        for e in range(args.num_epochs):\r\n",
    "            sess.run(tf.assign(model.lr,\r\n",
    "                               args.learning_rate * (args.decay_rate ** e)))\r\n",
    "            data_loader.reset_batch_pointer()\r\n",
    "            state = sess.run(model.initial_state)\r\n",
    "            for b in range(data_loader.num_batches):\r\n",
    "                start = time.time()\r\n",
    "                x, y = data_loader.next_batch()\r\n",
    "                feed = {model.input_data: x, model.targets: y}\r\n",
    "                for i, (c, h) in enumerate(model.initial_state):\r\n",
    "                    feed[c] = state[i].c\r\n",
    "                    feed[h] = state[i].h\r\n",
    "                train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\r\n",
    "\r\n",
    "                # instrument for tensorboard\r\n",
    "                summ, train_loss, state, _ = sess.run([summaries, model.cost, model.final_state, model.train_op], feed)\r\n",
    "                writer.add_summary(summ, e * data_loader.num_batches + b)\r\n",
    "\r\n",
    "                end = time.time()\r\n",
    "                print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\r\n",
    "                      .format(e * data_loader.num_batches + b,\r\n",
    "                              args.num_epochs * data_loader.num_batches,\r\n",
    "                              e, train_loss, end - start))\r\n",
    "                if (e * data_loader.num_batches + b) % args.save_every == 0\\\r\n",
    "                        or (e == args.num_epochs-1 and\r\n",
    "                            b == data_loader.num_batches-1):\r\n",
    "                    # save for the last result\r\n",
    "                    checkpoint_path = os.path.join(args.save_dir, 'model.ckpt')\r\n",
    "                    saver.save(sess, checkpoint_path,\r\n",
    "                               global_step=e * data_loader.num_batches + b)\r\n",
    "                    print(\"model saved to {}\".format(checkpoint_path))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('2021-music-generation': conda)"
  },
  "interpreter": {
   "hash": "c16c382a13fd833fe0c08c84fb164c3fac519413390891b24d99a8d8fd07836a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}